{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ded05db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from cca_zoo.deepmodels import (\n",
    "    DCCA,\n",
    "    DCCA_NOI,\n",
    "    DCCA_SDL,\n",
    "    #BarlowTwins,\n",
    "    get_dataloaders,\n",
    "    \n",
    ")\n",
    "from cca_zoo.deepmodels.utils import architectures, objectives\n",
    "from cca_zoo.plotting import pairplot_label\n",
    "from cca_zoo.data import CCA_Dataset\n",
    "from cca_zoo.models import CCA\n",
    "from cca_zoo.model_selection import GridSearchCV\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import crosstab\n",
    "from scipy.stats import hypergeom\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch import nn\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.integration.pytorch_lightning import tune\n",
    "os.chdir('../raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b5dcf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Files:\n",
    "    def __init__(self, filename):\n",
    "        self.file = filename\n",
    "        \n",
    "    def write_to_file(self, data):\n",
    "        with open(self.file, 'wb') as f:\n",
    "            pickle.dump(data, f) \n",
    "        return None\n",
    "    \n",
    "    def load_pickle(self):\n",
    "        data = pd.read_pickle(self.file)\n",
    "        return data\n",
    "    \n",
    "    def load_csv(self, sep, usecols=None):\n",
    "        data = pd.read_csv(self.file, sep=sep, usecols=usecols)\n",
    "        return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f475c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load df with all info\n",
    "path = './df_classes_max3_embeddings.pickle'\n",
    "df_all = Files(path).load_pickle()[:10000]#just a subset for scripting\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0e52552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCCA:\n",
    "    def __init__(self, df_all,batch_size = 768,num_workers = 6,\\\n",
    "                latent_dims=100, epochs=300, lr=0.001): #default dims determined after iteratin 10:50 dims \n",
    "        \n",
    "        self.df_all = df_all\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.v1='ms2ds'\n",
    "        self.v2 = 'mol2vec'\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.sdl_lr = 0.025118864315095822#0.01#lr (picked after running lr_finder)\n",
    "        self.dcca_lr = 5.623413251903491e-08 #lr\n",
    "        self.latent_dims=latent_dims\n",
    "        self.optim = 'sgd'\n",
    "        self.activation = nn.Tanh()\n",
    "        self.objective = objectives.CCA\n",
    "        self.encoder_1_layers = (500,500)\n",
    "        self.encoder_2_layers = (500,500)\n",
    "        seed_everything(15)\n",
    "        \n",
    "        \n",
    "    def split_data(self,test_size=0.2,\\\n",
    "                   random_state=None,stratify=None): # thinking of removing this one\n",
    "        \n",
    "        if random_state != None and stratify == None:\n",
    "            train_df, test_df = \\\n",
    "            train_test_split(self.df_all, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        elif random_state == None and stratify != None:\n",
    "            train_df, test_df = \\\n",
    "            train_test_split(self.df_all, test_size=test_size,stratify=self.df_all[stratify])\n",
    "        else:\n",
    "            train_df, test_df = \\\n",
    "            train_test_split(self.df_all, test_size=test_size, random_state=42)\n",
    "        \n",
    "        return train_df, test_df \n",
    "    \n",
    "    def gen_views(self,v1='ms2ds',v2='mol2vec'):\n",
    "        \n",
    "        #split test, train\n",
    "        train_df, test_df= self.split_data(test_size=0.2,random_state=42)\n",
    "        \n",
    "        #Split train dataset into train and validation set\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "        \n",
    "        \n",
    "        #extract the 2 view, v1 == spectra embeddings, v2==structure embeddings\n",
    "        v1_train, v1_test = np.array([x for x in train_df[v1]]), np.array([x for x in test_df[v1]])\n",
    "        v2_train, v2_test = np.array([x for x in train_df[v2]]), np.array([x for x in test_df[v2]])\n",
    "\n",
    "        # validation\n",
    "        v1_val, v2_val = np.array([x for x in val_df[v1]]), np.array([x for x in val_df[v2]])\n",
    "        \n",
    "        #update self dfs\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.val_df = val_df\n",
    "        \n",
    "        # not memory efficient !!!\n",
    "        self.v1_train, self.v1_test = v1_train, v1_test\n",
    "        self.v2_train, self.v2_test = v2_train, v2_test\n",
    "        self.v1_val, self.v2_val = v1_val, v2_val\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def deepcca_encoders(self):\n",
    "        # define encoders\n",
    "        self.encoder_1 = architectures.Encoder(\n",
    "                                      latent_dims = self.latent_dims, \n",
    "                                      feature_size = self.v1_size,\n",
    "                                      layer_sizes = self.encoder_1_layers,\n",
    "                                      activation = self.activation\n",
    "                                    )\n",
    "                                     \n",
    "        self.encoder_2 = architectures.Encoder(\n",
    "                                      latent_dims=self.latent_dims, \n",
    "                                      feature_size=self.v2_size, \n",
    "                                      layer_sizes=self.encoder_2_layers,\n",
    "                                      activation = self.activation\n",
    "                                     )\n",
    "       \n",
    "        return None#[encoder_1, encoder_2]\n",
    "        \n",
    "    \n",
    "    def deepcca_dataloaders(self):\n",
    "        \n",
    "        #v1_train,v1_test, v2_train,v2_test, v1_val, v2_val = \\\n",
    "        self.gen_views(v1=self.v1, v2=self.v2)\n",
    "        \n",
    "        #creat CCA dataset \n",
    "        train_dataset = CCA_Dataset([self.v1_train, self.v2_train])\n",
    "        test_dataset = CCA_Dataset([self.v1_test, self.v2_test])\n",
    "        val_dataset = CCA_Dataset([self.v1_val, self.v2_val])\n",
    "        \n",
    "        #update features size\n",
    "        self.v1_size = self.v1_train.shape[1]\n",
    "        self.v2_size = self.v2_train.shape[1]\n",
    "        self.N = len(train_dataset)\n",
    "        \n",
    "        #set N (for sdl; equal len train dataset)\n",
    "        self.N = len(train_dataset)\n",
    "        \n",
    "        #loaders\n",
    "        self.train_loader , self.val_loader = get_dataloaders(train_dataset, \\\n",
    "                                                    val_dataset,batch_size=self.batch_size,\\\n",
    "                                                    num_workers=self.num_workers,drop_last=False)\n",
    "        self.test_loader = get_dataloaders(test_dataset,\\\n",
    "                                      batch_size=self.batch_size, \\\n",
    "                                      num_workers=self.num_workers,drop_last=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def train_cca(self): #only for comparison with other deep models\n",
    "        \n",
    "       \n",
    "        \n",
    "        #define and train cca model\n",
    "        print('\\n','-'*20,'\\n Training CCA\\n','-'*20)\n",
    "        cca = CCA(latent_dims=self.latent_dims).fit((self.v1_train, self.v2_train))\n",
    "        self.cca = cca\n",
    "        return None#cca\n",
    "    \n",
    "    def train_sdl(self, checkpoint=None, logger=None,lam=0.0001,enable_progress_bar=True ):\n",
    "        \n",
    "        \n",
    "        # 2. SDL\n",
    "        sdl = DCCA_SDL(self.latent_dims,\n",
    "                       optimizer=self.optim,\n",
    "                       N=self.N, \n",
    "                       encoders = [self.encoder_1,self.encoder_2],\n",
    "                       lam=0.0001, \n",
    "                       lr=self.sdl_lr,\n",
    "                       dropout=0.05,\n",
    "                       objective=self.objective) \n",
    "\n",
    "        \n",
    "        \n",
    "        #define the trainer\n",
    "        \n",
    "        self.trainer = pl.Trainer(#default_root_dir=default_root_dir,\n",
    "                             logger = logger,\n",
    "                             max_epochs=self.epochs, #enable early stoppage instead of specifiying num epochs                           \n",
    "                             log_every_n_steps=1,\n",
    "                             val_check_interval = 1, #`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
    "                             \n",
    "                             callbacks=[\n",
    "                                checkpoint,\n",
    "                                 #pl.callbacks.early_stopping.EarlyStopping(monitor=\"val/l2\") # early stopage to reduce overfitting\n",
    "                             ],\n",
    "                            enable_progress_bar=enable_progress_bar,\n",
    "                            auto_lr_find = True\n",
    "                                )#,\n",
    "        \n",
    "        #callbacks=[pl.callbacks.early_stopping.EarlyStopping(monitor=\"train/sdl\")])# early stopage to reduce overfitting\n",
    "        \n",
    "        print('\\n','-'*20,'\\n Training SDL\\n','-'*20)\n",
    "        self.trainer.fit(sdl, self.train_loader,self.val_loader)\n",
    "        self.sdl = sdl\n",
    "        return None#sdl\n",
    "    \n",
    "    def train_dcca(self):\n",
    "        \n",
    "       \n",
    "        \n",
    "        # 2. DCCA\n",
    "        dcca = DCCA(self.latent_dims,\n",
    "                    optimizer=self.optim,\n",
    "                    encoders = [self.encoder_1,self.encoder_2],\n",
    "                    lr=self.dcca_lr,\n",
    "                    objective=self.objective) \n",
    "\n",
    "        #train\n",
    "        #tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"pl_logs/dcca\")\n",
    "        trainer = pl.Trainer(default_root_dir=\"./dcca\",max_epochs=self.epochs,log_every_n_steps=1)#,\n",
    "        \n",
    "        #callbacks=[pl.callbacks.early_stopping.EarlyStopping(monitor=\"train/sdl\")])# early stopage to reduce overfitting\n",
    "\n",
    "        print('\\n','-'*20,'\\n Training DCCA\\n','-'*20)\n",
    "        trainer.fit(dcca, self.train_loader,self.val_loader)\n",
    "        \n",
    "        self.dcca = dcca\n",
    "        \n",
    "        return None #dcca\n",
    "    \n",
    "    \n",
    "    \n",
    "    def score(self,model,dataset): \n",
    "        \"\"\"\n",
    "        model: either 'cca', 'dcca', 'sdl'\n",
    "        dataset: 'train', 'test', or 'val'\n",
    "        \n",
    "        returns: correlation \n",
    "        \"\"\"\n",
    "       # for cca models \n",
    "        #m = eval(model)\n",
    "        \n",
    "        #specify data to transform\n",
    "        if dataset == 'train':\n",
    "            v1,v2, loader = self.v1_train, self.v2_train, self.train_loader\n",
    "        elif dataset == 'test':\n",
    "            v1,v2, loader = self.v1_test, self.v2_test, self.test_loader\n",
    "        elif dataset == 'val':\n",
    "            v1,v2, loader = self.v1_val, self.v2_val, self.val_loader\n",
    "        \n",
    "        if model == 'cca':\n",
    "            corr = self.cca.score([v1,v2])\n",
    "        \n",
    "        if model == 'sdl':\n",
    "            corr = self.sdl.score(loader)\n",
    "        \n",
    "        elif model == 'dcca':\n",
    "            corr = self.dcca.score(loader)\n",
    "       \n",
    "        return corr\n",
    "    def update_z_scores(self,dataset, z1,z2,cols):\n",
    "        #update train df with transformed z scores\n",
    "            if dataset == 'train':\n",
    "                \n",
    "                self.train_df[cols[0]] = [x for x in z1]\n",
    "                self.train_df[cols[1]] = [x for x in z2]\n",
    "                \n",
    "            #update test df\n",
    "            if dataset == 'test':\n",
    "                self.test_df[cols[0]] = [x for x in z1]\n",
    "                self.test_df[cols[1]] = [x for x in z2]\n",
    "            \n",
    "            #update val df\n",
    "            if dataset == 'val':\n",
    "                self.val_df[cols[0]] = [x for x in z1]\n",
    "                self.val_df[cols[1]] = [x for x in z2]\n",
    "            return None\n",
    "                \n",
    "        \n",
    "    \n",
    "    def transform(self,model,dataset):\n",
    "        \"\"\"\n",
    "        model: either 'cca', 'dcca', 'sdl': of course the model must have been fitted :)\n",
    "        loader: is similar data loader used to train either sdl/dcca\n",
    "        dataset: either 'train', 'test', 'val'\n",
    "        \n",
    "        returns transformed data; view1,view2\n",
    "        \"\"\"\n",
    "        \n",
    "        #specify data to transform\n",
    "        if dataset == 'train':\n",
    "            v1,v2, loader = self.v1_train, self.v2_train, self.train_loader\n",
    "        elif dataset == 'test':\n",
    "            v1,v2, loader = self.v1_test, self.v2_test, self.test_loader\n",
    "        elif dataset == 'val':\n",
    "            v1,v2, loader = self.v1_val, self.v2_val, self.val_loader\n",
    "        \n",
    "        \n",
    "        #specify the model for transformation\n",
    "        if model == 'cca':\n",
    "            z1,z2 = self.cca.transform([v1,v2]) #transform\n",
    "            self.update_z_scores(dataset,z1,z2,cols=['cca_z1','cca_z2']) # update the df with z scores            \n",
    "    \n",
    "            \n",
    "        if model == 'sdl':\n",
    "            z1,z2 = self.sdl.transform(loader)\n",
    "            self.update_z_scores(dataset,z1,z2,cols=['sdl_z1','sdl_z2'])\n",
    "                \n",
    "        \n",
    "        if model == 'dcca':\n",
    "            z1,z2 = self.dcca.transform(loader)\n",
    "            self.update_z_scores(dataset,z1,z2,cols=['dcca_z1','dcca_z2'])\n",
    "        \n",
    "        \n",
    "        return None##z1,z2; can be found in self.<df[model_z]>       \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a54ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 15\n"
     ]
    }
   ],
   "source": [
    "# Initiate deepcca objec\n",
    "Models = DeepCCA(df_all)\n",
    "\n",
    "# generate data loaders and cca v1,v2\n",
    "Models.deepcca_dataloaders()\n",
    "\n",
    "# set up the encoders\n",
    "Models.deepcca_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1cbaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SDL\n",
    "sdl = DCCA_SDL(config['latent_dims'],\n",
    "                optimizer=config['optimizer'],\n",
    "                N=Models.N, \n",
    "                encoders = [Models.encoder_1,Models.encoder_2],\n",
    "                lam=0.0001, \n",
    "                lr=Models.sdl_lr,\n",
    "                dropout=0.05,\n",
    "                objective=Models.objective) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27f5d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"loss\": \"val/l2\"}\n",
    "ray_tune_callback = TuneReportCallback(metrics, on=\"validation_end\")\n",
    "\n",
    "# Defining a search space!\n",
    "config = {\n",
    " \"optimizer\": tune.choice(['sgd', 'adam', 'adamw']),\n",
    " \n",
    " #\"lr\": tune.loguniform(1e-4, 1e-1),\n",
    " #\"batch_size\": tune.choice([128, 128*2, 128*3],\n",
    "#\"latent_dims\": tune.choice([10,20,30]), \n",
    "#\"dropout\": tune.choice([0.05,0.1,0.15,0.2,0.25]))\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c63ee115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up logger\n",
    "version =  f'testing_ray_tune'\n",
    "   \n",
    "experiment_dir = './sdl_logs'\n",
    "    \n",
    "checkpoint = ModelCheckpoint(save_last=True,\n",
    "                                       monitor=\"val/l2\",\n",
    "                                       mode = 'min')\n",
    "    \n",
    "logger = TensorBoardLogger(save_dir=experiment_dir, \n",
    "                                   name='ray_tune',\n",
    "                                   version = version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2297f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune(config, epochs=10, gpus=0):\n",
    "    \n",
    "    \n",
    "    #set up logger\n",
    "    version =  f'testing_ray_tune'\n",
    "   \n",
    "    experiment_dir = './sdl_logs'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(save_last=True,\n",
    "                                       monitor=\"val/l2\",\n",
    "                                       mode = 'min')\n",
    "    \n",
    "    logger = TensorBoardLogger(save_dir=experiment_dir, \n",
    "                                   name='ray_tune',\n",
    "                                   version = version)\n",
    "    \n",
    "    \n",
    "    sdl = DCCA_SDL(Models.latent_dims,\n",
    "                optimizer=config['optimizer'],\n",
    "                N=Models.N, \n",
    "                encoders = [Models.encoder_1,Models.encoder_2],\n",
    "                lam=0.0001, \n",
    "                lr=Models.sdl_lr,\n",
    "                dropout=0.05,\n",
    "                objective=Models.objective)\n",
    "    \n",
    "    trainer = pl.Trainer(#default_root_dir=default_root_dir,\n",
    "    logger = logger,\n",
    "    max_epochs=10, #enable early stoppage instead of specifiying num epochs                           \n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval = 1, #`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
    "    callbacks=[\n",
    "        checkpoint,\n",
    "        #pl.callbacks.early_stopping.EarlyStopping(monitor=\"val/l2\") # early stopage to reduce overfitting\n",
    "        ray_tune_callback\n",
    "              ],\n",
    "    enable_progress_bar=True,\n",
    "    auto_lr_find = True\n",
    "    )\n",
    "    \n",
    "    trainer.fit(sdl,Models.train_loader,Models.val_loader)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-06 16:20:17</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:25.28        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.1/15.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.85 GiB heap, 0.0/1.42 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th>optimizer  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_49faa_00000</td><td>RUNNING </td><td>127.0.0.1:19992</td><td>adam       </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         121.358</td><td style=\"text-align: right;\">27.8511</td></tr>\n",
       "<tr><td>train_tune_49faa_00001</td><td>RUNNING </td><td>127.0.0.1:18944</td><td>adamw      </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00002</td><td>RUNNING </td><td>127.0.0.1:19040</td><td>adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00003</td><td>RUNNING </td><td>127.0.0.1:19960</td><td>adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00004</td><td>RUNNING </td><td>127.0.0.1:8876 </td><td>adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00005</td><td>RUNNING </td><td>127.0.0.1:21384</td><td>sgd        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00006</td><td>RUNNING </td><td>127.0.0.1:17532</td><td>adamw      </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00007</td><td>RUNNING </td><td>127.0.0.1:21956</td><td>adamw      </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00008</td><td>PENDING </td><td>               </td><td>sgd        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_tune_49faa_00009</td><td>PENDING </td><td>               </td><td>adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:09,721\tWARNING worker.py:1851 -- Warning: The actor ImplicitFunc is very large (82 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2023-01-06 16:18:09,952\tWARNING util.py:244 -- The `start_trial` operation took 2.384 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \r",
      "Sanity Checking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:17,682\tWARNING util.py:244 -- The `start_trial` operation took 1.042 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m \r",
      "Sanity Checking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:25,834\tWARNING util.py:244 -- The `start_trial` operation took 1.084 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19040)\u001b[0m \r",
      "Sanity Checking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:34,021\tWARNING util.py:244 -- The `start_trial` operation took 1.197 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19960)\u001b[0m \r",
      "Sanity Checking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:43,142\tWARNING util.py:244 -- The `start_trial` operation took 1.445 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=8876)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:53,473\tWARNING util.py:244 -- The `start_trial` operation took 1.979 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s]\n",
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=21384)\u001b[0m \r",
      "Sanity Checking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:19:09,754\tWARNING util.py:244 -- The `start_trial` operation took 2.534 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\n",
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=17532)\u001b[0m \r",
      "Sanity Checking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:19:24,215\tWARNING util.py:244 -- The `start_trial` operation took 1.945 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m   | Name     | Type       | Params\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 0 | encoders | ModuleList | 852 K \n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 1 | mse      | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 2 | bns      | ModuleList | 0     \n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m ----------------------------------------\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 852 K     Trainable params\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 852 K     Total params\n",
      "\u001b[2m\u001b[36m(func pid=21956)\u001b[0m 3.409     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "                                                                           \n",
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s] \n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   5%|▌         | 1/20 [01:00<19:04, 60.22s/it, loss=2.17, v_num=tune, train/objective=2.170, train/l2=1.990, train/sdl=1.79e+3]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 2023-01-06 16:19:54.336370: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m 2023-01-06 16:19:54.342852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]                            \n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  10%|█         | 2/20 [01:16<11:31, 38.43s/it, loss=2.17, v_num=tune, train/objective=2.170, train/l2=1.990, train/sdl=1.79e+3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_49faa_00000</td><td>2023-01-06_16-20-21</td><td>False </td><td>                </td><td>5c4ad47068bd47ba87bb0091e1c2bc9a</td><td>LLL       </td><td style=\"text-align: right;\">                        16</td><td style=\"text-align: right;\">32.1081</td><td>127.0.0.1</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\">             124.483</td><td style=\"text-align: right;\">          0.554675</td><td style=\"text-align: right;\">       124.483</td><td style=\"text-align: right;\"> 1673018421</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  16</td><td>49faa_00000</td><td style=\"text-align: right;\">   0.00598478</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|█         | 2/20 [01:17<11:38, 38.83s/it, loss=2.17, v_num=tune, train/objective=2.170, train/l2=1.990, train/sdl=1.79e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  15%|█▌        | 3/20 [01:18<07:22, 26.01s/it, loss=2.35, v_num=tune, train/objective=2.530, train/l2=2.070, train/sdl=4.6e+3] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  20%|██        | 4/20 [01:18<05:12, 19.55s/it, loss=2.35, v_num=tune, train/objective=2.530, train/l2=2.070, train/sdl=4.6e+3]\n",
      "Epoch 0:  20%|██        | 4/20 [01:18<05:13, 19.61s/it, loss=2.35, v_num=tune, train/objective=2.530, train/l2=2.070, train/sdl=4.6e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  25%|██▌       | 5/20 [01:18<03:56, 15.77s/it, loss=2.56, v_num=tune, train/objective=2.970, train/l2=2.210, train/sdl=7.65e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  30%|███       | 6/20 [01:18<03:04, 13.16s/it, loss=2.56, v_num=tune, train/objective=2.970, train/l2=2.210, train/sdl=7.65e+3]\n",
      "Epoch 0:  30%|███       | 6/20 [01:19<03:04, 13.20s/it, loss=2.56, v_num=tune, train/objective=2.970, train/l2=2.210, train/sdl=7.65e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  35%|███▌      | 7/20 [01:19<02:27, 11.37s/it, loss=2.49, v_num=tune, train/objective=2.310, train/l2=1.550, train/sdl=7.58e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  40%|████      | 8/20 [01:19<01:59,  9.96s/it, loss=2.49, v_num=tune, train/objective=2.310, train/l2=1.550, train/sdl=7.58e+3]\n",
      "Epoch 0:  40%|████      | 8/20 [01:19<01:59, 10.00s/it, loss=2.49, v_num=tune, train/objective=2.310, train/l2=1.550, train/sdl=7.58e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  45%|████▌     | 9/20 [01:20<01:38,  8.91s/it, loss=2.47, v_num=tune, train/objective=2.370, train/l2=1.520, train/sdl=8.51e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  50%|█████     | 10/20 [01:20<01:20,  8.03s/it, loss=2.47, v_num=tune, train/objective=2.370, train/l2=1.520, train/sdl=8.51e+3]\n",
      "Epoch 0:  50%|█████     | 10/20 [01:20<01:20,  8.06s/it, loss=2.47, v_num=tune, train/objective=2.370, train/l2=1.520, train/sdl=8.51e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  55%|█████▌    | 11/20 [01:20<01:06,  7.35s/it, loss=2.3, v_num=tune, train/objective=1.480, train/l2=0.965, train/sdl=5.17e+3] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  60%|██████    | 12/20 [01:20<00:53,  6.75s/it, loss=2.3, v_num=tune, train/objective=1.480, train/l2=0.965, train/sdl=5.17e+3]\n",
      "Epoch 0:  60%|██████    | 12/20 [01:21<00:54,  6.77s/it, loss=2.3, v_num=tune, train/objective=1.480, train/l2=0.965, train/sdl=5.17e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  65%|██████▌   | 13/20 [01:21<00:43,  6.27s/it, loss=2.18, v_num=tune, train/objective=1.420, train/l2=1.000, train/sdl=4.16e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 14/20 [01:21<00:34,  5.83s/it, loss=2.18, v_num=tune, train/objective=1.420, train/l2=1.000, train/sdl=4.16e+3]\n",
      "Epoch 0:  70%|███████   | 14/20 [01:21<00:35,  5.85s/it, loss=2.18, v_num=tune, train/objective=1.420, train/l2=1.000, train/sdl=4.16e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  75%|███████▌  | 15/20 [01:22<00:27,  5.48s/it, loss=2.08, v_num=tune, train/objective=1.380, train/l2=1.000, train/sdl=3.76e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  80%|████████  | 16/20 [01:22<00:20,  5.14s/it, loss=2.08, v_num=tune, train/objective=1.380, train/l2=1.000, train/sdl=3.76e+3]\n",
      "Epoch 0:  80%|████████  | 16/20 [01:22<00:20,  5.16s/it, loss=2.08, v_num=tune, train/objective=1.380, train/l2=1.000, train/sdl=3.76e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 0:  85%|████████▌ | 17/20 [01:22<00:14,  4.87s/it, loss=2, v_num=tune, train/objective=1.360, train/l2=1.000, train/sdl=3.57e+3]   \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0:  90%|█████████ | 18/20 [01:22<00:09,  4.61s/it, loss=2, v_num=tune, train/objective=1.360, train/l2=1.000, train/sdl=3.57e+3]\n",
      "Epoch 0:   5%|▌         | 1/20 [01:10<22:19, 70.48s/it, loss=2.17, v_num=tune, train/objective=2.170, train/l2=1.990, train/sdl=1.79e+3]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:  90%|█████████ | 18/20 [01:23<00:09,  4.62s/it, loss=2, v_num=tune, train/objective=1.360, train/l2=1.000, train/sdl=3.57e+3]\n",
      "                                                                      \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 2023-01-06 16:20:16.602869: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "\u001b[2m\u001b[36m(func pid=18944)\u001b[0m 2023-01-06 16:20:16.603149: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  95%|█████████▌| 19/20 [01:23<00:04,  4.38s/it, loss=1.93, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.47e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 0: 100%|██████████| 20/20 [01:23<00:00,  4.17s/it, loss=1.93, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.47e+3]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Epoch 0: 100%|██████████| 20/20 [01:23<00:00,  4.18s/it, loss=1.93, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.47e+3]\n",
      "Epoch 0: 100%|██████████| 20/20 [01:23<00:00,  4.18s/it, loss=1.93, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.47e+3]\n",
      "Epoch 1:   0%|          | 0/20 [00:00<?, ?it/s, loss=1.93, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.47e+3]         \n",
      "Epoch 1:   5%|▌         | 1/20 [00:00<00:05,  3.52it/s, loss=1.88, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.5e+3] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 1:  10%|█         | 2/20 [00:00<00:03,  5.00it/s, loss=1.88, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.5e+3]\n",
      "Epoch 1:  10%|█         | 2/20 [00:00<00:03,  4.99it/s, loss=1.88, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.5e+3]\n",
      "Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[:, None]\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 2/20 [00:00<00:06,  2.74it/s, loss=1.88, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.5e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 1:  15%|█▌        | 3/20 [00:01<00:05,  2.94it/s, loss=1.84, v_num=tune, train/objective=1.360, train/l2=1.000, train/sdl=3.58e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 1:  20%|██        | 4/20 [00:01<00:04,  3.53it/s, loss=1.84, v_num=tune, train/objective=1.360, train/l2=1.000, train/sdl=3.58e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[:, None]\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|██        | 4/20 [00:01<00:05,  2.91it/s, loss=1.84, v_num=tune, train/objective=1.360, train/l2=1.000, train/sdl=3.58e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 1:  25%|██▌       | 5/20 [00:01<00:04,  3.02it/s, loss=1.8, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.53e+3] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 1:  30%|███       | 6/20 [00:01<00:04,  3.38it/s, loss=1.8, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.53e+3]\n",
      "Epoch 1:  30%|███       | 6/20 [00:01<00:04,  3.03it/s, loss=1.8, v_num=tune, train/objective=1.350, train/l2=1.000, train/sdl=3.53e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 1:  35%|███▌      | 7/20 [00:02<00:04,  3.13it/s, loss=1.77, v_num=tune, train/objective=1.340, train/l2=1.000, train/sdl=3.42e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 1:  40%|████      | 8/20 [00:02<00:03,  3.40it/s, loss=1.77, v_num=tune, train/objective=1.340, train/l2=1.000, train/sdl=3.42e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[:, None]\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|████      | 8/20 [00:02<00:04,  2.97it/s, loss=1.77, v_num=tune, train/objective=1.340, train/l2=1.000, train/sdl=3.42e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 1:  45%|████▌     | 9/20 [00:02<00:03,  3.06it/s, loss=1.74, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.33e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  50%|█████     | 10/20 [00:03<00:03,  3.28it/s, loss=1.74, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.33e+3]\n",
      "Epoch 1:  50%|█████     | 10/20 [00:03<00:03,  3.03it/s, loss=1.74, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.33e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 1:  55%|█████▌    | 11/20 [00:03<00:02,  3.08it/s, loss=1.71, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.3e+3] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 1:  60%|██████    | 12/20 [00:03<00:02,  3.26it/s, loss=1.71, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.3e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[:, None]\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m C:\\Users\\lmeli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m   c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  60%|██████    | 12/20 [00:03<00:02,  3.06it/s, loss=1.71, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.3e+3]\n",
      "                                                                      \u001b[A\n",
      "Epoch 1:  65%|██████▌   | 13/20 [00:04<00:02,  3.03it/s, loss=1.69, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.29e+3]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(func pid=19992)\u001b[0m \n",
      "Epoch 1:  70%|███████   | 14/20 [00:04<00:01,  3.19it/s, loss=1.69, v_num=tune, train/objective=1.330, train/l2=1.000, train/sdl=3.29e+3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import partial\n",
    "analysis = tune.run(\n",
    " partial(train_tune,gpus=4),config=config,num_samples=10\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03654561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.errorbar(data= df, x= 'x',  y='mean', yerr='std',               \n",
    "             ecolor='red', color=sns.color_palette()[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af14604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Files:\n",
    "    def __init__(self, filename):\n",
    "        self.file = filename\n",
    "        \n",
    "    def write_to_file(self, data):\n",
    "        with open(self.file, 'wb') as f:\n",
    "            pickle.dump(data, f) \n",
    "        return None\n",
    "    \n",
    "    def load_pickle(self):\n",
    "        data = pd.read_pickle(self.file)\n",
    "        return data\n",
    "    \n",
    "    def load_csv(self, sep, usecols=None):\n",
    "        data = pd.read_csv(self.file, sep=sep, usecols=usecols)\n",
    "        return data\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12750a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanis = Files('./GNPS_15_12_2021_pos_tanimoto_scores.pickle').load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d31c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>inchikey14</th>\n",
       "      <th>LFTLOKWAGJYHHR</th>\n",
       "      <th>BQDXDGDOYPUUOD</th>\n",
       "      <th>VEPUCZUJLKAVNM</th>\n",
       "      <th>PXPSEALQIQRPQY</th>\n",
       "      <th>HDZVRBPBPCZCJG</th>\n",
       "      <th>SXJIZQPZESTWLD</th>\n",
       "      <th>JDOFZOKGCYYUER</th>\n",
       "      <th>WGTCMJBJRPKENJ</th>\n",
       "      <th>FCCDDURTIIUXBY</th>\n",
       "      <th>FDLLEBFMOIHMNM</th>\n",
       "      <th>...</th>\n",
       "      <th>RJAHLSXSRQXGGI</th>\n",
       "      <th>VKJTXCWIQDBMLE</th>\n",
       "      <th>NFIHKFSODJJLGC</th>\n",
       "      <th>NHLBOKNHQIEJIH</th>\n",
       "      <th>QABASLXUKXNHMC</th>\n",
       "      <th>XGVJWXAYKUHDOO</th>\n",
       "      <th>MNKNQKOOKLVXDB</th>\n",
       "      <th>CQKNELOTFUSOTP</th>\n",
       "      <th>MHCYVCDXRQGUFW</th>\n",
       "      <th>NMCMVEXMLSARCJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inchikey14</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LFTLOKWAGJYHHR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057353</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.053269</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.055453</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.056204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049612</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>0.060065</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.095833</td>\n",
       "      <td>0.050964</td>\n",
       "      <td>0.050159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BQDXDGDOYPUUOD</th>\n",
       "      <td>0.057353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>0.215026</td>\n",
       "      <td>0.242169</td>\n",
       "      <td>0.176221</td>\n",
       "      <td>0.296270</td>\n",
       "      <td>0.195915</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.430151</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>0.218014</td>\n",
       "      <td>0.321244</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.272672</td>\n",
       "      <td>0.147776</td>\n",
       "      <td>0.317369</td>\n",
       "      <td>0.253207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEPUCZUJLKAVNM</th>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286316</td>\n",
       "      <td>0.113158</td>\n",
       "      <td>0.152310</td>\n",
       "      <td>0.208607</td>\n",
       "      <td>0.264908</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.186620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.167925</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.152523</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>0.251228</td>\n",
       "      <td>0.226978</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.289835</td>\n",
       "      <td>0.231393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PXPSEALQIQRPQY</th>\n",
       "      <td>0.053269</td>\n",
       "      <td>0.215026</td>\n",
       "      <td>0.286316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134357</td>\n",
       "      <td>0.185499</td>\n",
       "      <td>0.342992</td>\n",
       "      <td>0.344860</td>\n",
       "      <td>0.081680</td>\n",
       "      <td>0.257655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243169</td>\n",
       "      <td>0.248216</td>\n",
       "      <td>0.351724</td>\n",
       "      <td>0.207021</td>\n",
       "      <td>0.299073</td>\n",
       "      <td>0.376868</td>\n",
       "      <td>0.351122</td>\n",
       "      <td>0.073363</td>\n",
       "      <td>0.362462</td>\n",
       "      <td>0.374658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDZVRBPBPCZCJG</th>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.242169</td>\n",
       "      <td>0.113158</td>\n",
       "      <td>0.134357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145266</td>\n",
       "      <td>0.205817</td>\n",
       "      <td>0.136898</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.240987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139401</td>\n",
       "      <td>0.275825</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.157074</td>\n",
       "      <td>0.223055</td>\n",
       "      <td>0.192202</td>\n",
       "      <td>0.190231</td>\n",
       "      <td>0.166329</td>\n",
       "      <td>0.196615</td>\n",
       "      <td>0.175919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20889 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "inchikey14      LFTLOKWAGJYHHR  BQDXDGDOYPUUOD  VEPUCZUJLKAVNM  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR        1.000000        0.057353        0.042969   \n",
       "BQDXDGDOYPUUOD        0.057353        1.000000        0.162866   \n",
       "VEPUCZUJLKAVNM        0.042969        0.162866        1.000000   \n",
       "PXPSEALQIQRPQY        0.053269        0.215026        0.286316   \n",
       "HDZVRBPBPCZCJG        0.069264        0.242169        0.113158   \n",
       "\n",
       "inchikey14      PXPSEALQIQRPQY  HDZVRBPBPCZCJG  SXJIZQPZESTWLD  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR        0.053269        0.069264        0.055453   \n",
       "BQDXDGDOYPUUOD        0.215026        0.242169        0.176221   \n",
       "VEPUCZUJLKAVNM        0.286316        0.113158        0.152310   \n",
       "PXPSEALQIQRPQY        1.000000        0.134357        0.185499   \n",
       "HDZVRBPBPCZCJG        0.134357        1.000000        0.145266   \n",
       "\n",
       "inchikey14      JDOFZOKGCYYUER  WGTCMJBJRPKENJ  FCCDDURTIIUXBY  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR        0.048193        0.053296        0.052863   \n",
       "BQDXDGDOYPUUOD        0.296270        0.195915        0.089888   \n",
       "VEPUCZUJLKAVNM        0.208607        0.264908        0.082418   \n",
       "PXPSEALQIQRPQY        0.342992        0.344860        0.081680   \n",
       "HDZVRBPBPCZCJG        0.205817        0.136898        0.102000   \n",
       "\n",
       "inchikey14      FDLLEBFMOIHMNM  ...  RJAHLSXSRQXGGI  VKJTXCWIQDBMLE  \\\n",
       "inchikey14                      ...                                   \n",
       "LFTLOKWAGJYHHR        0.056204  ...        0.049612        0.054762   \n",
       "BQDXDGDOYPUUOD        0.460000  ...        0.185547        0.430151   \n",
       "VEPUCZUJLKAVNM        0.186620  ...        0.157480        0.167925   \n",
       "PXPSEALQIQRPQY        0.257655  ...        0.243169        0.248216   \n",
       "HDZVRBPBPCZCJG        0.240987  ...        0.139401        0.275825   \n",
       "\n",
       "inchikey14      NFIHKFSODJJLGC  NHLBOKNHQIEJIH  QABASLXUKXNHMC  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR        0.053929        0.060065        0.049683   \n",
       "BQDXDGDOYPUUOD        0.180851        0.218014        0.321244   \n",
       "VEPUCZUJLKAVNM        0.233333        0.152523        0.228311   \n",
       "PXPSEALQIQRPQY        0.351724        0.207021        0.299073   \n",
       "HDZVRBPBPCZCJG        0.136986        0.157074        0.223055   \n",
       "\n",
       "inchikey14      XGVJWXAYKUHDOO  MNKNQKOOKLVXDB  CQKNELOTFUSOTP  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR        0.052980        0.049046        0.095833   \n",
       "BQDXDGDOYPUUOD        0.297297        0.272672        0.147776   \n",
       "VEPUCZUJLKAVNM        0.251228        0.226978        0.080844   \n",
       "PXPSEALQIQRPQY        0.376868        0.351122        0.073363   \n",
       "HDZVRBPBPCZCJG        0.192202        0.190231        0.166329   \n",
       "\n",
       "inchikey14      MHCYVCDXRQGUFW  NMCMVEXMLSARCJ  \n",
       "inchikey14                                      \n",
       "LFTLOKWAGJYHHR        0.050964        0.050159  \n",
       "BQDXDGDOYPUUOD        0.317369        0.253207  \n",
       "VEPUCZUJLKAVNM        0.289835        0.231393  \n",
       "PXPSEALQIQRPQY        0.362462        0.374658  \n",
       "HDZVRBPBPCZCJG        0.196615        0.175919  \n",
       "\n",
       "[5 rows x 20889 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d5437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04296875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanis.loc['LFTLOKWAGJYHHR', 'VEPUCZUJLKAVNM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ebf2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>inchikey14</th>\n",
       "      <th>LFTLOKWAGJYHHR</th>\n",
       "      <th>BQDXDGDOYPUUOD</th>\n",
       "      <th>VEPUCZUJLKAVNM</th>\n",
       "      <th>PXPSEALQIQRPQY</th>\n",
       "      <th>HDZVRBPBPCZCJG</th>\n",
       "      <th>SXJIZQPZESTWLD</th>\n",
       "      <th>JDOFZOKGCYYUER</th>\n",
       "      <th>WGTCMJBJRPKENJ</th>\n",
       "      <th>FCCDDURTIIUXBY</th>\n",
       "      <th>FDLLEBFMOIHMNM</th>\n",
       "      <th>...</th>\n",
       "      <th>RJAHLSXSRQXGGI</th>\n",
       "      <th>VKJTXCWIQDBMLE</th>\n",
       "      <th>NFIHKFSODJJLGC</th>\n",
       "      <th>NHLBOKNHQIEJIH</th>\n",
       "      <th>QABASLXUKXNHMC</th>\n",
       "      <th>XGVJWXAYKUHDOO</th>\n",
       "      <th>MNKNQKOOKLVXDB</th>\n",
       "      <th>CQKNELOTFUSOTP</th>\n",
       "      <th>MHCYVCDXRQGUFW</th>\n",
       "      <th>NMCMVEXMLSARCJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inchikey14</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LFTLOKWAGJYHHR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BQDXDGDOYPUUOD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEPUCZUJLKAVNM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PXPSEALQIQRPQY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDZVRBPBPCZCJG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20889 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "inchikey14      LFTLOKWAGJYHHR  BQDXDGDOYPUUOD  VEPUCZUJLKAVNM  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR             1.0             NaN             NaN   \n",
       "BQDXDGDOYPUUOD             NaN             1.0             NaN   \n",
       "VEPUCZUJLKAVNM             NaN             NaN             1.0   \n",
       "PXPSEALQIQRPQY             NaN             NaN             NaN   \n",
       "HDZVRBPBPCZCJG             NaN             NaN             NaN   \n",
       "\n",
       "inchikey14      PXPSEALQIQRPQY  HDZVRBPBPCZCJG  SXJIZQPZESTWLD  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR             NaN             NaN             NaN   \n",
       "BQDXDGDOYPUUOD             NaN             NaN             NaN   \n",
       "VEPUCZUJLKAVNM             NaN             NaN             NaN   \n",
       "PXPSEALQIQRPQY             1.0             NaN             NaN   \n",
       "HDZVRBPBPCZCJG             NaN             1.0             NaN   \n",
       "\n",
       "inchikey14      JDOFZOKGCYYUER  WGTCMJBJRPKENJ  FCCDDURTIIUXBY  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR             NaN             NaN             NaN   \n",
       "BQDXDGDOYPUUOD             NaN             NaN             NaN   \n",
       "VEPUCZUJLKAVNM             NaN             NaN             NaN   \n",
       "PXPSEALQIQRPQY             NaN             NaN             NaN   \n",
       "HDZVRBPBPCZCJG             NaN             NaN             NaN   \n",
       "\n",
       "inchikey14      FDLLEBFMOIHMNM  ...  RJAHLSXSRQXGGI  VKJTXCWIQDBMLE  \\\n",
       "inchikey14                      ...                                   \n",
       "LFTLOKWAGJYHHR             NaN  ...             NaN             NaN   \n",
       "BQDXDGDOYPUUOD             NaN  ...             NaN             NaN   \n",
       "VEPUCZUJLKAVNM             NaN  ...             NaN             NaN   \n",
       "PXPSEALQIQRPQY             NaN  ...             NaN             NaN   \n",
       "HDZVRBPBPCZCJG             NaN  ...             NaN             NaN   \n",
       "\n",
       "inchikey14      NFIHKFSODJJLGC  NHLBOKNHQIEJIH  QABASLXUKXNHMC  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR             NaN             NaN             NaN   \n",
       "BQDXDGDOYPUUOD             NaN             NaN             NaN   \n",
       "VEPUCZUJLKAVNM             NaN             NaN             NaN   \n",
       "PXPSEALQIQRPQY             NaN             NaN             NaN   \n",
       "HDZVRBPBPCZCJG             NaN             NaN             NaN   \n",
       "\n",
       "inchikey14      XGVJWXAYKUHDOO  MNKNQKOOKLVXDB  CQKNELOTFUSOTP  \\\n",
       "inchikey14                                                       \n",
       "LFTLOKWAGJYHHR             NaN             NaN             NaN   \n",
       "BQDXDGDOYPUUOD             NaN             NaN             NaN   \n",
       "VEPUCZUJLKAVNM             NaN             NaN             NaN   \n",
       "PXPSEALQIQRPQY             NaN             NaN             NaN   \n",
       "HDZVRBPBPCZCJG             NaN             NaN             NaN   \n",
       "\n",
       "inchikey14      MHCYVCDXRQGUFW  NMCMVEXMLSARCJ  \n",
       "inchikey14                                      \n",
       "LFTLOKWAGJYHHR             NaN             NaN  \n",
       "BQDXDGDOYPUUOD             NaN             NaN  \n",
       "VEPUCZUJLKAVNM             NaN             NaN  \n",
       "PXPSEALQIQRPQY             NaN             NaN  \n",
       "HDZVRBPBPCZCJG             NaN             NaN  \n",
       "\n",
       "[5 rows x 20889 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7de2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
